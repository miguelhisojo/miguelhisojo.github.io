<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Data Science | MIGUEL ANGEL HISOJO</title>
    <link>https://miguelhisojo.github.io/category/data-science/</link>
      <atom:link href="https://miguelhisojo.github.io/category/data-science/index.xml" rel="self" type="application/rss+xml" />
    <description>Data Science</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><lastBuildDate>Tue, 11 Aug 2020 21:22:33 +0200</lastBuildDate>
    <image>
      <url>https://miguelhisojo.github.io/images/icon_hu777885f414bcc18ff5c79c4bbb0d0e17_655_512x512_fill_lanczos_center_2.png</url>
      <title>Data Science</title>
      <link>https://miguelhisojo.github.io/category/data-science/</link>
    </image>
    
    <item>
      <title>WEB SCRAPING</title>
      <link>https://miguelhisojo.github.io/project/web-scraping/</link>
      <pubDate>Tue, 11 Aug 2020 21:22:33 +0200</pubDate>
      <guid>https://miguelhisojo.github.io/project/web-scraping/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;scraping.png&#34; alt=&#34;scraping.png&#34;&gt;&lt;/p&gt;
&lt;h1 id=&#34;how-to-see-the-big-picture&#34;&gt;How to see the big picture?&lt;/h1&gt;
&lt;p&gt;Web scraping, the answer to get ahead in a world producing billions of data points in seconds.&lt;/p&gt;
&lt;h2 id=&#34;what-is-it&#34;&gt;What is it?&lt;/h2&gt;
&lt;p&gt;According to Wikipedia&amp;hellip;&lt;/p&gt;
&lt;blockquote&gt;
Web scraping, web harvesting, or web data extraction is data scraping used for extracting data from websites. Web scraping software may access the World Wide Web directly using the Hypertext Transfer Protocol or through a web browser. While web scraping can be done manually by a software user, the term typically refers to automated processes implemented using a bot or web crawler. It is a form of copying, in which specific data is gathered and copied from the web, typically into a central local database or spreadsheet, for later retrieval or analysis.
&lt;/blockquote&gt;
&lt;h1 id=&#34;in-short&#34;&gt;In short:&lt;/h1&gt;
&lt;p&gt;Web scraping, allows you to parse HTML code from websites and save it in a spreadsheet or database giving you data insights.&lt;/p&gt;
&lt;h1 id=&#34;why-is-it-needed-&#34;&gt;Why is it needed &amp;hellip;&lt;/h1&gt;
&lt;p&gt;Everybody has to take decisions, and making informed decisions is key for any purpose you have. Web scraping allows you to make decisions and understand how other actors in your domain are getting ahead.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;For businesses, this allows them to get the data, information, statistics, or knowledge of the latest trends and understand their competitors.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;For analysts to allow them to get pricing intelligence, competitor analysis, market research, or sentiment analysis, you need to scrape actual data from the web to arrive at a suitable strategy.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;who-needs-it&#34;&gt;Who needs it&lt;/h1&gt;
&lt;p&gt;You need this, If you work as:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;entrepreneur&lt;/li&gt;
&lt;li&gt;recruiter&lt;/li&gt;
&lt;li&gt;marketer&lt;/li&gt;
&lt;li&gt;researcher&lt;/li&gt;
&lt;li&gt;analyst&lt;/li&gt;
&lt;li&gt;journalist&lt;/li&gt;
&lt;li&gt;data scientist&lt;/li&gt;
&lt;li&gt;medical professional&lt;/li&gt;
&lt;li&gt;politician&lt;/li&gt;
&lt;li&gt;lawyer&lt;/li&gt;
&lt;li&gt;accountant&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;lets-code&#34;&gt;Let&amp;rsquo;s code.&lt;/h1&gt;
&lt;p&gt;For web scraping, we will need to install some python libraries like Beautiful Soup, requests and lxml&lt;/p&gt;
&lt;p&gt;We need to pull data from websites, for this, we will use a Python library called 
&lt;a href=&#34;https://www.crummy.com/software/BeautifulSoup/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Beaitiful Soup&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;bs.png&#34; alt=&#34;bs.png&#34;&gt;&lt;/p&gt;
&lt;h1 id=&#34;install-the-libraries&#34;&gt;Install the libraries&lt;/h1&gt;
&lt;h2 id=&#34;beautiful-soup&#34;&gt;Beautiful Soup&lt;/h2&gt;
&lt;p&gt;To install 
&lt;a href=&#34;https://www.crummy.com/software/BeautifulSoup/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Beaitiful Soup&lt;/a&gt;, only type in your terminal&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;pip install beautifulsoup4&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This will allow you to get the latest version of the library. Beautiful Soup sits on top of popular Python parsers like lxml and html5lib, allowing you to try out different parsing strategies or trade speed for flexibility.&lt;/p&gt;
&lt;h2 id=&#34;requests&#34;&gt;Requests&lt;/h2&gt;
&lt;p&gt;The 
&lt;a href=&#34;https://requests.readthedocs.io/en/master/library&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Requests&lt;/a&gt; library is the standard to make an HTTP request in python. Install the library typing in your terminal:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;pip install requests&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;lxml&#34;&gt;lxml&lt;/h2&gt;
&lt;p&gt;We will needa “parser” for interpreting the HTML page.  The 
&lt;a href=&#34;https://lxml.de/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;lxml&lt;/a&gt; library combines the speed and XML feature completeness of libxml2 and libxslt libraries with the simplicity of a native Python API, mostly compatible but superior to the well-known ElementTree API. Install the library typing in your terminal:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;pip install lxml&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;center-font-size30-examplefont-center&#34;&gt;&lt;center&gt; &lt;font size=&#34;30&#34;&gt; Example&lt;/font&gt; &lt;/center&gt;&lt;/h1&gt;
&lt;h2 id=&#34;center-extracting-article-information-from-a-blog-center&#34;&gt;&lt;center&gt; Extracting article information from a blog. &lt;/center&gt;&lt;/h2&gt;
&lt;p&gt;This example will show you how web scraping is valuable for journalists and business owners. Allowing them to get data from different sources for market analysis.&lt;/p&gt;
&lt;h3 id=&#34;importing-our-libraries&#34;&gt;Importing our libraries&lt;/h3&gt;
&lt;p&gt;We need to import our Beautiful Soup (bs4) and requests libraries as follows:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from bs4 import BeautifulSoup
import requests

&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;now-we-are-going-to-import-an-article-from-the-entrepreneur-blog-on-the-topic-millennials&#34;&gt;Now we are going to import an article from the entrepreneur blog on the topic &lt;em&gt;millennials&lt;/em&gt;&lt;/h3&gt;
&lt;p&gt;For this, we are going to use the method &lt;strong&gt;GET&lt;/strong&gt; from our &lt;em&gt;requests&lt;/em&gt; library. The GET method indicates that you’re trying to get or retrieve data from a specified resource.&lt;/p&gt;
&lt;p&gt;The HTTP request will send us a response 200, this code means the request was valid.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;response = requests.get(&#39;https://www.entrepreneur.com/topic/millennials&#39;)
print(response)

&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;&amp;lt;Response [200]&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;we-want-to-look-at-the-code&#34;&gt;We want to look at the code&lt;/h3&gt;
&lt;p&gt;Now, we want to make sure that we actually extract the HTML code from the request we made. Besides, we want to see the actual text result of the HTML page, you can read the &lt;em&gt;.text&lt;/em&gt; property of this object.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;source=response.text 
#print(source) 
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;now-we-can-make-the-soup&#34;&gt;Now, we can make the Soup&lt;/h3&gt;
&lt;p&gt;We will make a variable called &lt;em&gt;soup&lt;/em&gt; that will call the Beautiful soup constructor, this will receive a string. In our case, these will be our source variable, and our &lt;em&gt;lxml&lt;/em&gt; parser.&lt;/p&gt;
&lt;p&gt;Note, that there are different parsers that we can use for this, but the difference in performance is not that big, feel free to try them all.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;soup = BeautifulSoup(source, &#39;lxml&#39;) 
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;extracting-information-about-the-article&#34;&gt;Extracting information about the article&lt;/h3&gt;
&lt;p&gt;Our &lt;em&gt;soup&lt;/em&gt; variable contains all the HTML code of the blog, however, we want to extract only what is interesting to us, like the title of the article and the summary.&lt;/p&gt;
&lt;p&gt;To find out what we need to extract, we can go to our web page and open the &lt;em&gt;developer tools&lt;/em&gt; as follows:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;right-click&lt;/em&gt; on the title of an article&lt;/li&gt;
&lt;li&gt;on the menu, click on &lt;em&gt;inspect&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;en_block.png&#34; alt=&#34;en_block.png&#34;&gt;&lt;/p&gt;
&lt;p&gt;Once we have localized the HTML tags that contain the information necessary for us, we can extract it with the find function. The information we need is:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The title&lt;/li&gt;
&lt;li&gt;Summary of the article.&lt;/li&gt;
&lt;li&gt;Link&lt;/li&gt;
&lt;li&gt;Author&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The title is contained inside an &lt;em&gt;a tag&lt;/em&gt;, as well as the &lt;em&gt;link&lt;/em&gt; URL, the summary is inside &lt;em&gt;div&lt;/em&gt; with class deck and the author inside a &lt;em&gt;span&lt;/em&gt; element.&lt;/p&gt;
&lt;p&gt;Now, it is important to understand where these elements are wrapped on, so we can see that they are wrapped inside a &lt;strong&gt;div&lt;/strong&gt; with class &lt;strong&gt;block&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;First, we will begin by extracting the wrapping element. For doing this, we will use the find()  attribute from bs4, that receives the element &lt;strong&gt;div&lt;/strong&gt; and the class.&lt;/p&gt;
&lt;p&gt;The word &lt;strong&gt;class&lt;/strong&gt; is a reserved word in Python, so this function uses **class_** to differentiate between these two.&lt;/p&gt;
&lt;p&gt;Now we can extract a block of code and display it in our terminal, for this we will use the &lt;strong&gt;prettify()&lt;/strong&gt; function. A pretty-printed block will allow you to see the indentation of the HTML code, so you can actually notice the tags and elements you need to access.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;article = soup.find(&#39;div&#39;,class_=&#39;block&#39;)

print(article.prettify())

&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;&amp;lt;div class=&amp;quot;block&amp;quot;&amp;gt;
 &amp;lt;a class=&amp;quot;kicker ga-click&amp;quot; data-ga-action=&amp;quot;kicker&amp;quot; data-ga-category=&amp;quot;topic-millennials-playlist-latest-feature&amp;quot; data-ga-label=&amp;quot;playlist.1&amp;quot; href=&amp;quot;/topic/millennials&amp;quot;&amp;gt;
  Millennials
 &amp;lt;/a&amp;gt;
 &amp;lt;h3&amp;gt;
  &amp;lt;a class=&amp;quot;ga-click&amp;quot; data-ga-action=&amp;quot;headline&amp;quot; data-ga-category=&amp;quot;topic-millennials-playlist-latest-feature&amp;quot; data-ga-label=&amp;quot;playlist.1&amp;quot; href=&amp;quot;/article/348092&amp;quot;&amp;gt;
   7 Interesting Financial Facts About Millennials
  &amp;lt;/a&amp;gt;
 &amp;lt;/h3&amp;gt;
 &amp;lt;div class=&amp;quot;deck&amp;quot;&amp;gt;
  The millennial generation has its virtues and shortcomings, but more often than not, millennials are considered to be financially indisciplined.
 &amp;lt;/div&amp;gt;
 &amp;lt;div class=&amp;quot;byline&amp;quot;&amp;gt;
  &amp;lt;a class=&amp;quot;ga-click&amp;quot; data-ga-action=&amp;quot;authorname&amp;quot; data-ga-category=&amp;quot;topic-millennials-playlist-latest-feature&amp;quot; data-ga-label=&amp;quot;playlist.1&amp;quot; href=&amp;quot;/author/portia-antonia-alexis&amp;quot;&amp;gt;
   &amp;lt;span class=&amp;quot;name&amp;quot;&amp;gt;
    Portia Antonia Alexis
   &amp;lt;/span&amp;gt;
  &amp;lt;/a&amp;gt;
  &amp;lt;span class=&amp;quot;spacer&amp;quot;&amp;gt;
   |
  &amp;lt;/span&amp;gt;
  &amp;lt;span class=&amp;quot;readtime&amp;quot;&amp;gt;
   11 min read
  &amp;lt;/span&amp;gt;
 &amp;lt;/div&amp;gt;
&amp;lt;/div&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;extracting-the-headline&#34;&gt;Extracting the headline&lt;/h2&gt;
&lt;p&gt;In our previous line, we notice the title is inside an &lt;em&gt;$&amp;lt;$a$&amp;gt;$&lt;/em&gt; tag, which is inside an &lt;em&gt;$&amp;lt;$h3$&amp;gt;$&lt;/em&gt; element&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;&amp;lt;h3&amp;gt;
    &amp;lt;a href=&amp;quot;/article/348092&amp;quot;&amp;gt;7 Interesting Financial Facts About Millennials &amp;lt;/a&amp;gt; 
&amp;lt;/h3&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We can access the HTML elements, making reference to the object containing the block code, in this case, we called &lt;em&gt;article&lt;/em&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;for article in soup.find_all(&#39;div&#39;,class_=&#39;block&#39;):headline= article.h3.a.text
print(headline)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;---------------------------------------------------------------------------

AttributeError                            Traceback (most recent call last)

&amp;lt;ipython-input-13-85011acff508&amp;gt; in &amp;lt;module&amp;gt;
----&amp;gt; 1 for article in soup.find_all(&#39;div&#39;,class_=&#39;block&#39;):headline= article.h3.a.text
      2 print(headline)


AttributeError: &#39;NoneType&#39; object has no attribute &#39;a&#39;
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;extracting-the-summary&#34;&gt;Extracting the summary&lt;/h2&gt;
&lt;p&gt;The same way, we can extrac the summary, contained inside a &lt;em&gt;$&amp;lt;$div$&amp;gt;$&lt;/em&gt; element with class name &lt;em&gt;deck&lt;/em&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;sumary = article.find(&#39;div&#39;,class_=&#39;deck&#39; ).text
print(sumary)
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;extracting-the-url&#34;&gt;Extracting the URL&lt;/h2&gt;
&lt;p&gt;The URL is an attribute &lt;em&gt;href&lt;/em&gt; inside the title tag, we can access attributes by specifying it on brackets next to the element where it is contained as follows:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;link =  article.h3.a[&#39;href&#39;]
link = f&#39;https://www.entrepreneur.com{link}&#39;
print(link)
&lt;/code&gt;&lt;/pre&gt;
&lt;h1 id=&#34;center-font-size30-extract--all-the-articles-in-a-page-save-it-on-a-csv--fontcenter&#34;&gt;&lt;center&gt; &lt;font size=&#34;30&#34;&gt; Extract  all the articles in a page, save it on a CSV  &lt;/font&gt;&lt;/center&gt;&lt;/h1&gt;
&lt;h2 id=&#34;the-find_all-method&#34;&gt;The find_all* method&lt;/h2&gt;
&lt;p&gt;We want to get all articles, we’ll need to use the &lt;em&gt;find_all()&lt;/em&gt; method to extract all the tags with all the blocks containing an article.&lt;/p&gt;
&lt;h2 id=&#34;we-need-exceptions&#34;&gt;We need exceptions&lt;/h2&gt;
&lt;p&gt;Sometimes, a block might have a missing element, url, or a description. So we will use exceptions to pass when something goes wrong.&lt;/p&gt;
&lt;p&gt;We will save every article inside a CSV file. Here is the full code of this example.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from bs4 import BeautifulSoup
import requests
import csv

source = requests.get(&#39;https://www.entrepreneur.com/topic/millennials&#39;).text
domain= &#39;https://www.entrepreneur.com/&#39;

soup = BeautifulSoup(source, &#39;lxml&#39;) 

with open(&#39;cms_file.csv&#39;,&#39;w&#39;) as csv_file:
    csv_writer=csv.writer(csv_file)
    csv_writer.writerow([&#39;headline&#39;,&#39;summary&#39;,&#39;link&#39;])

    for article in soup.find_all(&#39;div&#39;,class_=&#39;block&#39;):
        try:
            headline= article.h3.a.text
            #print(headline)

            sumary = article.find(&#39;div&#39;,class_=&#39;deck&#39; ).text
            #print(sumary)

            link =  article.h3.a[&#39;href&#39;]
            link = f&#39;https://www.entrepreneur.com{link}&#39;
            #print(link)

        except Exception as e:
            pass    


        csv_writer.writerow([headline,sumary,link ])



&lt;/code&gt;&lt;/pre&gt;
&lt;h1 id=&#34;the-resulting-csv-file&#34;&gt;The resulting CSV file&lt;/h1&gt;
&lt;p&gt;&lt;img src=&#34;CSV_FILE.png&#34; alt=&#34;CSV_FILE&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;now-try-it-on-financial-websites-or-investment-websites-and-use-pandas-to-get-the-most-of-your-data&#34;&gt;Now, try it on financial websites or investment websites, and use pandas to get the most of your data!&lt;/h2&gt;
</description>
    </item>
    
  </channel>
</rss>
